{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import PCA\n",
    "from numba import jit\n",
    "import numba\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "alphas = pd.read_csv(\"data_cutnorm.csv\")\n",
    "# alphas = pd.read_csv(\"data_residbarrarsector.csv\")\n",
    "base_data = pd.read_csv(\"base_data.csv\")\n",
    "# barra = pd.read_csv(\"barrar.csv\")\n",
    "barra = pd.read_hdf('barrar_risk.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若添加barra因子加入组合，需合并\n",
    "alphas = pd.merge(alphas, barra, on=['date', 'cn_code'], how='inner').dropna().reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加权方法\n",
    "1. **等权法**：所有因子等权重相加并重新进行标准化处理，对应`AlphasCombination._weighted_average`方法。\n",
    "\n",
    "2. **历史因子收益率（半衰）加权法**：计算因子历史收益率的算数平均值或半衰加权的历史平均收益率，作为因子加权的权重，对应`AlphasCombination._factor_return_weighting`方法。本例中使用默认半衰加权的方式，加权参数见后说明。\n",
    "\n",
    "3. **历史因子IC（半衰）加权法**：计算因子历史RankIC的算数平均值或半衰加权的历史平均RankIC，作为因子加权的权重，对应对应`AlphasCombination._history_ic_weighting`方法。本例中使用默认半衰加权的方式，加权参数见后说明。；\n",
    "\n",
    "4. **最大化ICIR加权法**：ICIR等于IC的期望值除以标准差。以历史因子平均IC值作为复合因子下一期IC的估计，以历史IC值的协方差矩阵作为对复合因子下一期波动率的估计，记$\\bm{w}^*=(w_1^*,w_2^*,\\dots,w_N^*)$为因子合成的权重，$\\bm{IC}=(\\overline{IC}_1, \\overline{IC}_2, \\dots,\\overline{IC}_N)^T$表示因子IC的均值向量，$\\Sigma$为因子IC的协方差矩阵，则问题变为 \n",
    "\n",
    "$$\\max ICIR=\\frac{\\bm{w}^T \\bm{IC}}{\\sqrt{\\bm{w}^T \\Sigma \\bm{w}}}$$ \n",
    "显式解为$\\bm{w}=\\Sigma^{-1} \\cdot \\bm{IC}$，此后进行归一化处理。实际操作中，需要添加约束条件$\\bm{w} \\geq \\bm{0}$，从而上述问题变为\n",
    "$$\\max ICIR=\\frac{\\bm{w}^T \\bm{IC}}{\\sqrt{\\bm{w}^T \\Sigma \\bm{w}}}$$\n",
    "$$\\text{s.t. }\\quad \\bm{w}\\geq 0$$ \n",
    "\n",
    "代码中，对应`AlphasCombination._max_icir_weighting`方法，加权权重由`_get_max_icir_weight_np`函数给出。此外，采用Ledoit & Wolf (2004)给出的压缩估计方法改善对真实协方差矩阵的估计，具体求解参考下方备注，对应`_shrinkage_covariance`函数。\n",
    "\n",
    "5. **最大化IC加权法**：同样解优化问题\n",
    "$$\\max IC=\\frac{\\bm{w}^T \\bm{IC}}{\\sqrt{\\bm{w}^T V \\bm{w}}}$$\n",
    "$$\\text{s.t. }\\quad \\bm{w}\\geq 0$$ \n",
    "其中相比最大化ICIR的优化方式，仅仅将$\\Sigma$替换成了$V$，即当前截面因子值的相关系数矩阵。在代码中，对应此外，`AlphasCombination._max_ic_weighting`方法，加权权重由`_get_max_ic_weight_np`函数给出。我们同样对样本因子值的协方差矩阵做上述压缩估计以获得无偏估计。\n",
    "\n",
    "6. **主成分分析估计法**：该方式直接对所有因子进行主成分分析降维，取第一主成分作为组合后的因子值。该方式的优势是组合结果通常较为稳定，不依赖于因子收益、IC/ICIR，但与此同时也可能因未充分利用历史信息而“欠拟合”。本研究中统一取总成分数为5的降维结果的第一主成分，对应`AlphasCombination._pca_weighting`方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 备注\n",
    "- **注1：半衰加权公式**：设半衰期参数为$H$，过去共有$T$期数据，加权权重$w=(w_1,w_2,\\dots,w_t)$, $w_1$是距离现在最远的一期权重。则有初始$w_t$\n",
    "\n",
    "$$w_t=2^{\\frac{t-T-1}{H}}, \\quad t=1,2,\\dots,T$$\n",
    "在实际操作中，需对上述权重进行归一化：\n",
    "$$w_t'=\\frac{w_t}{\\sum w_t}$$\n",
    "此方法可应用到历史IC加权组合，历史因子收益率加权组合等方式中，以提升近期因子表现的权重。本研究中，统一取$T=250,H=50$，即250个交易日历史数据（约1年）进行加权，权重每50个交易日变为原先的一半。\n",
    "\n",
    "- **注2**：为使得加权结果稳定，在\\textbf{因子组合模块}中使用的所有IC均为RankIC而非常规的PearsonIC\n",
    "\n",
    "- **注3：协方差矩阵的压缩估计。**\n",
    "设$\\Sigma^*$是对真实协方差矩阵$\\Sigma$在有限样本下的渐进一致估计，$S$是样本$X$的协方差矩阵，则需要找到$\\Sigma^*$，使得$$\\mathbb{E}\\left[||\\Sigma^*-\\Sigma||^2\\right]$$尽可能小，其中$||\\cdot||$是矩阵的Frobenius范数（即所有元素的均方根），也即$$||A||=\\sqrt{tr(AA^T)/N}$$ Ledoit和Wolf证明了对于样本$X=(x_t)$和其协方差矩阵$S(N\\times T)$，该问题的压缩估计为 $$\\Sigma^*=\\rho_1 I+\\rho_2 S$$ 其中 $$\\rho_1=\\frac{b^2}{d^2}m, \\quad \\rho_2=\\frac{a^2}{d^2}$$ $$m=||S-I||^2, \\quad d^2=||S-mI||^2, \\quad b_0^2=\\frac{1}{T^2}\\sum_{t=1}^T ||x_t \\cdot x_t^T-S||^2$$ $$b^2=\\min(b_0^2,d^2), \\quad a^2=d^2-b^2$$\n",
    "此方法应用在因子优化中，最大化IC和ICIR的组合方式的协方差矩阵估计中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def squared_fro(m):\n",
    "    '''\n",
    "    tr(AA^T)/n\n",
    "    '''\n",
    "    return np.trace(m.dot(m.T)) / m.shape[1]\n",
    "\n",
    "@jit\n",
    "def sum_squared_fro(x, s):\n",
    "    '''\n",
    "    sum_{n} ||xx^T-s||\n",
    "    '''\n",
    "    return squared_fro(x.reshape(-1, 1).dot(x.reshape(1, -1)) - s)\n",
    "\n",
    "@jit\n",
    "def _shrinkage_covariance(y: pd.DataFrame):\n",
    "    '''\n",
    "    Ledoit & Wolf (2004), Shrinkage of Covariance Matrix\n",
    "    '''\n",
    "    n_alphas = y.shape[1]\n",
    "    n_obs = y.shape[0]\n",
    "    sample_corr = pd.DataFrame(y).corr().values\n",
    "\n",
    "    m0 = sample_corr - np.identity(n_alphas)\n",
    "    m = squared_fro(m0)\n",
    "    d0 = sample_corr - m * np.identity(n_alphas)\n",
    "    d_squared = squared_fro(d0)\n",
    "    b0_squared = np.nansum(np.apply_along_axis(\\\n",
    "        sum_squared_fro, axis=1, arr=y, s=sample_corr)) / np.power(n_obs, 2)\n",
    "\n",
    "    b_squared = min(b0_squared, d_squared)\n",
    "    a_squared = d_squared - b_squared\n",
    "    rho1 = b_squared / d_squared * m\n",
    "    rho2 = a_squared / d_squared\n",
    "    sigma = rho1 * np.identity(n_alphas) + rho2 * sample_corr\n",
    "    return sigma\n",
    "\n",
    "@jit\n",
    "def _get_max_icir_weight_np(rankic: pd.DataFrame):\n",
    "    '''\n",
    "    Max ICIR weight, Sigma^{-1} times IC.mean\n",
    "    '''\n",
    "    sigma = _shrinkage_covariance(rankic)\n",
    "    weight_max_icir = np.linalg.inv(sigma).dot(rankic.mean(axis=0))\n",
    "    weight_max_icir = weight_max_icir / weight_max_icir.sum()\n",
    "    return weight_max_icir\n",
    "\n",
    "@jit\n",
    "def _get_max_ic_weight_np(v: pd.DataFrame):\n",
    "    '''\n",
    "    Max IC weight, V^{-1} times IC.mean\n",
    "    '''\n",
    "    if('date' in v.columns):\n",
    "        v.drop(columns='date', inplace=True)\n",
    "    sigma = _shrinkage_covariance(v)\n",
    "    weight_max_ic = np.linalg.inv(sigma).dot(v.mean(axis=0))\n",
    "    weight_max_ic = weight_max_ic / weight_max_ic.sum()\n",
    "\n",
    "    return pd.Series(weight_max_ic, index=v.columns)\n",
    "\n",
    "class AlphasCombination:\n",
    "    def __init__(self, alphas: pd.DataFrame, base_data: pd.DataFrame, \\\n",
    "        test_days=1, T=250, H=50, rankic=None):\n",
    "\n",
    "        # 保存alphas, base_data和标签\n",
    "        self.alphas = alphas\n",
    "        self.base_data = base_data\n",
    "        self.label_cols = ['date', 'cn_code']\n",
    "        self.alpha_cols = self.alphas.columns.drop(self.label_cols)\n",
    "        self.T = T\n",
    "        self.H = H\n",
    "        self.rankic = rankic\n",
    "        \n",
    "        # 初始化数据：合并，取出收益目标列\n",
    "        self._init_data(test_days)\n",
    "    \n",
    "    def _init_data(self, test_days=1):\n",
    "        '''\n",
    "        初始化数据：合并，取出收益目标列\n",
    "        '''\n",
    "        self.test_days = test_days\n",
    "        # 因变量选定为未来n日收益，由test_days指定\n",
    "        self.ylabel_col = self._get_ylabel_col(test_days)\n",
    "        # 删除未来目标收益（因变量）中为NaN的观测\n",
    "        self.data = pd.merge(alphas, base_data, on=['date', 'cn_code'], \\\n",
    "            how='left')\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_ylabel_col(test_days=1):\n",
    "        '''\n",
    "        指定因变量的未来收益周期数\n",
    "        '''\n",
    "        if(test_days == 1):\n",
    "            return 'adj_ret_p1'\n",
    "        elif(test_days == 5):\n",
    "            return 'adj_ret_p1_p5'\n",
    "        elif(test_days == 10):\n",
    "            return 'adj_ret_p1_p10'\n",
    "        elif(test_days == 20):\n",
    "            return 'adj_ret_p1_p20'\n",
    "        else:\n",
    "            raise ValueError('Test periods should be in [1, 5, 10, 20].')\n",
    "            \n",
    "    @property\n",
    "    def halflife_weight(self):\n",
    "        '''\n",
    "        半衰加权，默认T为250交易日，H为50\n",
    "        '''\n",
    "        return np.power(2, [(t - self.T - 1) / self.H for t in range(1, self.T + 1)])\n",
    "    \n",
    "    def _history_averaging(self, x, method='decay'):\n",
    "        '''\n",
    "        历史数据（因子收益/IC）加权平均\n",
    "        method仅当设置为decay时为半衰加权，否则为等权平均\n",
    "        '''\n",
    "        if(method == 'decay'):\n",
    "            assert len(x) == len(self.halflife_weight)\n",
    "            return np.nansum(x * self.halflife_weight) / np.sum(self.halflife_weight)\n",
    "        return np.mean(x, axis=0)\n",
    "    \n",
    "    def _weighted_average(self, x: pd.DataFrame, weight: pd.DataFrame):\n",
    "        '''\n",
    "        给定权重后进行加权平均\n",
    "        '''\n",
    "        try:\n",
    "            avg = (x[weight.columns] * weight.loc[x['date']].values).sum(axis=1)\n",
    "            return avg\n",
    "        except:\n",
    "            # 数据缺失，raise warning，返回全0值\n",
    "            print(\"Warning: No weight data for date \" + str(x['date'].values[0]))\n",
    "            return (x[weight.columns] * 0).sum(axis=1)\n",
    "    \n",
    "    def _get_wls_res(self, sub_data, value='params', test_days=1):\n",
    "        '''\n",
    "        Get WLS results\n",
    "        未来某时间段内收益率对中性化后的因子暴露进行WLS，得到系数为因子回报率\n",
    "        '''\n",
    "        # 回归前删除部分column，如日期和代码\n",
    "        x_cols = self.alphas.columns.drop(self.label_cols)\n",
    "        # 测试收益日数，默认为1\n",
    "        y_col = self._get_ylabel_col(test_days)\n",
    "        # 进行WLS回归，市值平方根加权\n",
    "        res = sm.WLS(sub_data[y_col], sm.add_constant(sub_data[x_cols]), \\\n",
    "            weights=np.sqrt(sub_data['cap']), missing='drop').fit()\n",
    "        # 返回需要的结果\n",
    "        if(value == 'params'):\n",
    "            return res.params\n",
    "        elif(value == 'tvalues'):\n",
    "            return res.tvalues\n",
    "        elif(value == 'pvalues'):\n",
    "            return res.pvalues\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported value\")\n",
    "\n",
    "    def _result_wrapping(self, results, name):\n",
    "        \"\"\"\n",
    "        Wrap the results series with date and code\n",
    "        \"\"\"\n",
    "        assert isinstance(results, pd.Series)\n",
    "        results_ = self.alphas[[self.label_cols]].reset_index().drop(\n",
    "            columns='index')\n",
    "        results_[name] = results.values\n",
    "        return results_\n",
    "    \n",
    "    def _average_weighting(self):\n",
    "        \"\"\"\n",
    "        Simple average of cross-sectional alphas\n",
    "        \"\"\"\n",
    "        if(self.rankic is None):\n",
    "            self._init_rankic(self.test_days)\n",
    "        sign = (self.rankic.mean() < 0) * (-1) + (self.rankic.mean() >= 0) * 1\n",
    "        self.average_alpha = (self.alphas.drop(columns=self.label_cols) * sign).mean(axis=1)\n",
    "        return self.average_alpha\n",
    "    \n",
    "    def _factor_return_weighting(self, test_days=1):\n",
    "\n",
    "        if(test_days != self.test_days):\n",
    "            self._init_data(test_days)\n",
    "        \n",
    "        # WLS回归系数，为因子收益率\n",
    "        data_dropna = self.data.dropna(subset=[self.ylabel_col])\n",
    "        wls_params = data_dropna.groupby('date').apply(self._get_wls_res, \\\n",
    "            value='params', test_days=test_days)\n",
    "        # 求过去T个交易日的滚动因子收益，按H个交易日作为半衰期做衰减加权\n",
    "        # 默认T为250，H为50，注意去除常数项\n",
    "        # NOTE: 权重向后平移Test Days，防止look-ahead bias\n",
    "        weight_ret = wls_params.drop(columns = 'const').rolling(self.T).apply(\n",
    "            self._history_averaging).shift(self.test_days)\n",
    "        # 对加权权重进行归一化，得到长度为T*M的每日因子权重数据\n",
    "        weight_ret = weight_ret.apply(lambda x: x / np.nansum(x), axis=1)\n",
    "        # 对每日的所有股票的横截面数据，每支股票的因子暴露均按当日的权重加权求和进行组合\n",
    "        self.ret_weighted_alpha = self.alphas.groupby('date').apply(\\\n",
    "            self._weighted_average, weight=weight_ret)\n",
    "        return self.ret_weighted_alpha\n",
    "    \n",
    "    def _init_rankic(self, test_days=1):\n",
    "\n",
    "        print(\"Initializing RankIC for Alphas now------------\")\n",
    "        if(test_days != self.test_days):\n",
    "            self._init_data(test_days)\n",
    "        \n",
    "        # 因子值排序\n",
    "        rank = self.alphas.drop(columns=['cn_code']).groupby('date').apply(\\\n",
    "            lambda x: x.rank(pct=True)).drop(columns='date')\n",
    "        # 添加日期\n",
    "        rank.insert(0, 'date', self.alphas['date'].values)\n",
    "        # 因变量（未来期限收益）排序\n",
    "        rank['rank_rtn'] = self.data.groupby('date')[\\\n",
    "            self.ylabel_col].rank(pct=True).values\n",
    "\n",
    "        # 计算rankic\n",
    "        self.rankic = rank.groupby('date').apply(\\\n",
    "            lambda x: x.corrwith(x['rank_rtn'])).drop(columns=['date', 'rank_rtn'])\n",
    "        print(\"RankIC Initialized!---------------------------\")\n",
    "        return rank\n",
    "\n",
    "    def _history_ic_weighting(self, test_days=1):\n",
    "\n",
    "        if(test_days != self.test_days):\n",
    "            self._init_data(test_days)\n",
    "        if(self.rankic is None):\n",
    "            self._init_rankic(test_days)\n",
    "        \n",
    "        # NOTE: 权重向后平移Test Days，防止look-ahead bias\n",
    "        weight_ic = self.rankic.rolling(self.T).apply(self._history_averaging).shift(self.test_days)\n",
    "        weight_ic = weight_ic.apply(lambda x: x / np.nansum(x), axis=1)\n",
    "        self.ic_weighted_alpha = self.alphas.groupby('date').apply(\\\n",
    "            self._weighted_average, weight=weight_ic)\n",
    "        return self.ic_weighted_alpha\n",
    "    \n",
    "    def _pca_weighting(self, n_components=5):\n",
    "        '''\n",
    "        对因子进行PCA变换，取第一主成分作为组合后的因子，默认主成分数为5\n",
    "        '''\n",
    "        pca = PCA(n_components=n_components)\n",
    "        first_comp = pca.fit_transform(self.alphas.drop(columns=self.label_cols))[:, 0]\n",
    "        self.pca_weighted_alpha = pd.Series(first_comp)\n",
    "        return self.pca_weighted_alpha\n",
    "    \n",
    "    def _max_icir_weighting(self, test_days=1):\n",
    "        '''\n",
    "        对因子进行最大化ICIR加权，公式见说明文档\n",
    "        '''\n",
    "        if(test_days != self.test_days):\n",
    "            self._init_data(test_days)\n",
    "        if(self.rankic is None):\n",
    "            self._init_rankic(test_days=test_days)\n",
    "        \n",
    "        # 对所有数据滚动T期按公式计算权重\n",
    "        # 注意：pd的rolling操作不支持在table上进行滚动，使用numba引擎保证计算可以实现\n",
    "        # NOTE: 权重向后平移Test Days，防止look-ahead bias\n",
    "        weight_max_icir = self.rankic.rolling(self.T, min_periods=self.T, \\\n",
    "            method='table').apply(_get_max_icir_weight_np, engine='numba', \\\n",
    "                raw=True, engine_kwargs={'nopython': False}).shift(self.test_days)\n",
    "        \n",
    "        # 加权平均\n",
    "        self.max_icir_weighted_alpha = self.alphas.groupby('date').apply(\\\n",
    "            self._weighted_average, weight=weight_max_icir)\n",
    "        return self.max_icir_weighted_alpha\n",
    "    \n",
    "    def _max_ic_weighting(self, test_days=1):\n",
    "        '''\n",
    "        对因子进行最大化IC加权，公式见说明文档\n",
    "        '''\n",
    "        if(test_days != self.test_days):\n",
    "            self._init_data(test_days)\n",
    "        \n",
    "        # 对每日的因子值截面相关性系数矩阵按公式计算权重\n",
    "        weight_max_ic = self.alphas.drop(columns=['cn_code']).groupby(\\\n",
    "            'date').apply(_get_max_ic_weight_np)\n",
    "        # 加权平均\n",
    "        self.max_ic_weighted_alpha = self.alphas.groupby('date').apply(\\\n",
    "            self._weighted_average, weight=weight_max_ic)\n",
    "        return self.max_ic_weighted_alpha\n",
    "    \n",
    "    def fit(self):\n",
    "        '''\n",
    "        汇总运行各个方法并保存结果，API接口\n",
    "        '''\n",
    "\n",
    "        print(\"Aggregation begins for future {:d} days of return\".format(self.test_days))\n",
    "        \n",
    "        print(\"Performing Average Weighting------------------\")\n",
    "        self._average_weighting()\n",
    "        print(\"Average Rating Finished!----------------------\\n\")\n",
    "\n",
    "        print(\"Performing PCA Weighting----------------------\")\n",
    "        self._pca_weighting()\n",
    "        print(\"PCA Rating Finished!--------------------------\\n\")\n",
    "\n",
    "        print(\"Performing History Factor Return Weighting----\")\n",
    "        self._factor_return_weighting(self.test_days)\n",
    "        print(\"Factor Return Weighting Finished!-------------\\n\")\n",
    "\n",
    "        print(\"Performing History IC Weighting---------------\")\n",
    "        self._history_ic_weighting(self.test_days)\n",
    "        print(\"History IC Weighting Finished!----------------\\n\")\n",
    "\n",
    "        print(\"Performing Maximizing ICIR Weighting----------\")\n",
    "        self._max_icir_weighting(self.test_days)\n",
    "        print(\"Maximizing ICIR Weighting Finished!-----------\\n\")\n",
    "\n",
    "        print(\"Performing Maximizing IC Weighting------------\")\n",
    "        self._max_ic_weighting(self.test_days)\n",
    "        print(\"Maximizing IC Weighting Finished!-------------\\n\")\n",
    "\n",
    "        print(\"Aggregation Finished! Organizing results now!\")\n",
    "\n",
    "        # 保存结果\n",
    "        self.alpha_aggregations = pd.DataFrame(\\\n",
    "            self.average_alpha.values, index = self.ret_weighted_alpha.index, \\\n",
    "            columns=['Average'])\n",
    "        self.alpha_aggregations.insert(0, 'cn_code', self.alphas['cn_code'].values)\n",
    "        self.alpha_aggregations['PCA'] = self.pca_weighted_alpha.values\n",
    "        self.alpha_aggregations['HistoryFactorReturn'] = self.ret_weighted_alpha.values\n",
    "        self.alpha_aggregations['HistoryIC'] = self.ic_weighted_alpha.values\n",
    "        self.alpha_aggregations['MaxICIR'] = self.max_icir_weighted_alpha.values\n",
    "        self.alpha_aggregations['MaxIC'] = self.max_ic_weighted_alpha.values\n",
    "        print(\"Result Organization Finished!-----------------\\n\")\n",
    "\n",
    "        print(\"Saving Your Results Now!----------------------\")\n",
    "        save_path = \"alpha_aggregations_\" + self.ylabel_col + \".h5\"\n",
    "        self.alpha_aggregations.to_hdf(save_path, key='stage', mode='w')\n",
    "        print(\"Aggregation Results Saved! ^_^ ---------------\")\n",
    "\n",
    "        return self.alpha_aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing RankIC for Alphas now------------\n",
      "RankIC Initialized!---------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          0.366047\n",
       "1         -0.274629\n",
       "2         -0.316559\n",
       "3         -0.084904\n",
       "4         -0.092602\n",
       "             ...   \n",
       "4404950   -0.223424\n",
       "4404951   -0.247717\n",
       "4404952   -0.261617\n",
       "4404953   -0.015019\n",
       "4404954    0.378353\n",
       "Length: 4404955, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average_generator = AlphasCombination(alphas, base_data, test_days=1)\n",
    "# average_generator._average_weighting()\n",
    "# avg_alpha = pd.DataFrame(average_generator.average_alpha, columns=['average'])\n",
    "# avg_alpha.insert(0, 'date', alphas.date)\n",
    "# avg_alpha.insert(1, 'cn_code', alphas.cn_code)\n",
    "# avg_alpha.to_hdf(\"alpha_aggregations_average_original.h5\", key='stage', mode='w', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation begins for future 1 days of return\n",
      "Performing Average Weighting------------------\n",
      "Initializing RankIC for Alphas now------------\n",
      "RankIC Initialized!---------------------------\n",
      "Average Rating Finished!----------------------\n",
      "\n",
      "Performing PCA Weighting----------------------\n",
      "PCA Rating Finished!--------------------------\n",
      "\n",
      "Performing History Factor Return Weighting----\n",
      "Factor Return Weighting Finished!-------------\n",
      "\n",
      "Performing History IC Weighting---------------\n",
      "History IC Weighting Finished!----------------\n",
      "\n",
      "Performing Maximizing ICIR Weighting----------\n",
      "Maximizing ICIR Weighting Finished!-----------\n",
      "\n",
      "Performing Maximizing IC Weighting------------\n",
      "Maximizing IC Weighting Finished!-------------\n",
      "\n",
      "Aggregation Finished! Organizing results now!\n",
      "Result Organization Finished!-----------------\n",
      "\n",
      "Saving Your Results Now!----------------------\n",
      "Aggregation Results Saved! ^_^ ---------------\n",
      "Aggregation begins for future 5 days of return\n",
      "Performing Average Weighting------------------\n",
      "Initializing RankIC for Alphas now------------\n",
      "RankIC Initialized!---------------------------\n",
      "Average Rating Finished!----------------------\n",
      "\n",
      "Performing PCA Weighting----------------------\n",
      "PCA Rating Finished!--------------------------\n",
      "\n",
      "Performing History Factor Return Weighting----\n",
      "Factor Return Weighting Finished!-------------\n",
      "\n",
      "Performing History IC Weighting---------------\n",
      "History IC Weighting Finished!----------------\n",
      "\n",
      "Performing Maximizing ICIR Weighting----------\n",
      "Maximizing ICIR Weighting Finished!-----------\n",
      "\n",
      "Performing Maximizing IC Weighting------------\n",
      "Maximizing IC Weighting Finished!-------------\n",
      "\n",
      "Aggregation Finished! Organizing results now!\n",
      "Result Organization Finished!-----------------\n",
      "\n",
      "Saving Your Results Now!----------------------\n",
      "Aggregation Results Saved! ^_^ ---------------\n",
      "Aggregation begins for future 10 days of return\n",
      "Performing Average Weighting------------------\n",
      "Initializing RankIC for Alphas now------------\n",
      "RankIC Initialized!---------------------------\n",
      "Average Rating Finished!----------------------\n",
      "\n",
      "Performing PCA Weighting----------------------\n",
      "PCA Rating Finished!--------------------------\n",
      "\n",
      "Performing History Factor Return Weighting----\n",
      "Warning: No weight data for date 20230203\n",
      "Warning: No weight data for date 20230206\n",
      "Factor Return Weighting Finished!-------------\n",
      "\n",
      "Performing History IC Weighting---------------\n",
      "History IC Weighting Finished!----------------\n",
      "\n",
      "Performing Maximizing ICIR Weighting----------\n",
      "Maximizing ICIR Weighting Finished!-----------\n",
      "\n",
      "Performing Maximizing IC Weighting------------\n",
      "Maximizing IC Weighting Finished!-------------\n",
      "\n",
      "Aggregation Finished! Organizing results now!\n",
      "Result Organization Finished!-----------------\n",
      "\n",
      "Saving Your Results Now!----------------------\n",
      "Aggregation Results Saved! ^_^ ---------------\n",
      "Aggregation begins for future 20 days of return\n",
      "Performing Average Weighting------------------\n",
      "Initializing RankIC for Alphas now------------\n",
      "RankIC Initialized!---------------------------\n",
      "Average Rating Finished!----------------------\n",
      "\n",
      "Performing PCA Weighting----------------------\n",
      "PCA Rating Finished!--------------------------\n",
      "\n",
      "Performing History Factor Return Weighting----\n",
      "Warning: No weight data for date 20221228\n",
      "Warning: No weight data for date 20221229\n",
      "Warning: No weight data for date 20221230\n",
      "Warning: No weight data for date 20230113\n",
      "Warning: No weight data for date 20230116\n",
      "Warning: No weight data for date 20230117\n",
      "Warning: No weight data for date 20230118\n",
      "Warning: No weight data for date 20230119\n",
      "Warning: No weight data for date 20230120\n",
      "Warning: No weight data for date 20230130\n",
      "Warning: No weight data for date 20230131\n",
      "Warning: No weight data for date 20230201\n",
      "Warning: No weight data for date 20230202\n",
      "Warning: No weight data for date 20230203\n",
      "Warning: No weight data for date 20230206\n",
      "Factor Return Weighting Finished!-------------\n",
      "\n",
      "Performing History IC Weighting---------------\n",
      "History IC Weighting Finished!----------------\n",
      "\n",
      "Performing Maximizing ICIR Weighting----------\n",
      "Maximizing ICIR Weighting Finished!-----------\n",
      "\n",
      "Performing Maximizing IC Weighting------------\n",
      "Maximizing IC Weighting Finished!-------------\n",
      "\n",
      "Aggregation Finished! Organizing results now!\n",
      "Result Organization Finished!-----------------\n",
      "\n",
      "Saving Your Results Now!----------------------\n",
      "Aggregation Results Saved! ^_^ ---------------\n"
     ]
    }
   ],
   "source": [
    "for test_days in [1, 5, 10, 20]:\n",
    "    generator = AlphasCombination(alphas, base_data, test_days=test_days)\n",
    "    generator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "406fc061deb33f0aa77d26ddb85a341d574dd3281c000087856ef3a4cde589f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
